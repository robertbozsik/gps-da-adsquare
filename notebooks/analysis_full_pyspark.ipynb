{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "agricultural-consumption",
   "metadata": {},
   "source": [
    "### installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m pip install --upgrade pip\n",
    "# python3 -m pip install numpy\n",
    "# python3 -m pip install pandas\n",
    "# python3 -m pip install shapely\n",
    "# brew install gdal # fiona dependency\n",
    "# python3 -m pip install fiona # geopandas dependency\n",
    "# python3 -m pip install pyproj # geopandas dependency\n",
    "# python3 -m pip install pygeos # geopandas dependency\n",
    "# python3 -m pip install geopandas\n",
    "# python3 -m pip install jupyter\n",
    "# python3 -m pip install folium\n",
    "# python3 -m pip install matplotlib\n",
    "# python3 -m pip install seaborn\n",
    "# python3 -m pip install findspark\n",
    "# python3 -m pip install apache-sedona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-pride",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import pytz # python timezones\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (16, 9)\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType, DecimalType\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame # loading boundaries data\n",
    "from shapely.geometry import Point, Polygon, shape # creating geospatial data\n",
    "from shapely import wkb, wkt # creating and parsing geospatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max number of processes (defaults to number of physical CPUs)\n",
    "num_processors = cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-robinson",
   "metadata": {},
   "source": [
    "### create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"adsquare assignment\")\n",
    "         .config(\"spark.serializer\", KryoSerializer.getName)\n",
    "         .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName)\n",
    "         .config('spark.jars.packages',\n",
    "                 'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.0.0-incubating,'\n",
    "                 'org.datasyslab:geotools-wrapper:geotools-24.0')\n",
    "         .config(\"spark.cores.max\", num_processors)\n",
    "         .getOrCreate()\n",
    "        )\n",
    "\n",
    "print(\"Spark {} session initialised\".format(spark.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sedona functions and types to Spark\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Sedona spatial indexing and partitioning config in Spark session\n",
    "# (no effect on the \"small\" spatial join query in this script. Will improve bigger queries)\n",
    "spark.conf.set(\"sedona.global.index\", \"true\")\n",
    "spark.conf.set(\"sedona.global.indextype\", \"rtree\")\n",
    "spark.conf.set(\"sedona.join.gridtype\", \"kdbtree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-savannah",
   "metadata": {},
   "source": [
    "### abbreviations\n",
    "**df** = Pandas DataFrame \\\n",
    "**gdf** = Geopandas GeoDataFrame \\\n",
    "**sdf** = Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-decrease",
   "metadata": {},
   "source": [
    "### stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-twenty",
   "metadata": {},
   "source": [
    "**stores_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = pd.read_csv(\"../../assignment_data/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-purple",
   "metadata": {},
   "source": [
    "**stores_sdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_sdf = stores_df.rename(columns={\"wkt\": \"polygon_store\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_sdf = spark.createDataFrame(stores_sdf).repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stores_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-amino",
   "metadata": {},
   "source": [
    "### GPS signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all gps_signal csv batches\n",
    "signals_sdf = (spark.read.format(\"csv\")\n",
    "               .option(\"header\", \"true\")\n",
    "               .load(\"../../assignment_data/full_data/*.csv\")).repartition(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of signals\n",
    "# signals_sdf.count() # 56 572 824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by utc_timestamp in ascending order\n",
    "signals_sdf = signals_sdf.orderBy(\"utc_timestamp\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-alpha",
   "metadata": {},
   "source": [
    "**convert utc timestamp to local time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_utc_ms_ts(utc_ms_ts) -> str:\n",
    "    \"\"\"Return a date (yyyy-mm-dd) from a string of utc timestamp in milliseconds (timezone = Europe/Berlin).\n",
    "\n",
    "    :param utc_ms_ts: Unix UTC timestamp in milliseconds (int or str)\n",
    "    :return: date yyyy-mm-dd (str)\n",
    "    \"\"\"\n",
    "    # convert from time stamp to datetime\n",
    "    utc_datetime = dt.datetime.utcfromtimestamp(int(utc_ms_ts) / 1000)\n",
    "    # set the timezone to UTC, and then convert to desired timezone\n",
    "    date = (utc_datetime\n",
    "            .replace(tzinfo=pytz.timezone('UTC'))\n",
    "            .astimezone(pytz.timezone('Europe/Berlin'))\n",
    "            .strftime('%Y-%m-%d'))\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_extractor = udf(date_from_utc_ms_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sdf = signals_sdf.withColumn(\"date\", utc_extractor(signals_sdf[\"utc_timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column \"utc_timestamp\"\n",
    "signals_sdf = signals_sdf.drop(\"utc_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-frame",
   "metadata": {},
   "source": [
    "**convert lat, lon to POINT ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_from_lon_lat(lon, lat) -> str:\n",
    "    \"\"\"Return a POINT (lon, lat) as a string from lon lat coordinates.\n",
    "\n",
    "    :param lon: longitude (string)\n",
    "    :param lat: latitude (string)\n",
    "    :return: POINT (lon, lat) as a string type\n",
    "    \"\"\"\n",
    "    lon = lon.strip()\n",
    "    lon = float(lon)\n",
    "    lon = round(lon, 7)\n",
    "    lon = str(lon)\n",
    "    \n",
    "    lat = lat.strip()\n",
    "    lat = float(lat)\n",
    "    lat = round(lat, 7)\n",
    "    lat = str(lat)\n",
    "    \n",
    "    return f\"POINT ({lon} {lat})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lat_extractor = udf(point_from_lon_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sdf = (signals_sdf.withColumn(\"point_signal\", \n",
    "                                      lon_lat_extractor(signals_sdf[\"lon\"], signals_sdf[\"lat\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-domain",
   "metadata": {},
   "source": [
    "### signals_stores_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary tables for SQL queries\n",
    "stores_sdf.createOrReplaceTempView(\"stores\")\n",
    "signals_sdf.createOrReplaceTempView(\"signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_stores_sdf = spark.sql(\n",
    "#     \"\"\"\n",
    "#     SELECT *\n",
    "#     FROM \n",
    "#         signals, \n",
    "#         stores\n",
    "#     WHERE ST_Intersects(ST_GeomFromText(stores.polygon_store), \n",
    "#                         ST_POINT(CAST(signals.lon AS Decimal(24,20)), CAST(signals.lat AS Decimal(24,20))))\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_sdf = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM \n",
    "        signals, \n",
    "        stores\n",
    "    WHERE ST_Intersects(ST_GeomFromText(stores.polygon_store), \n",
    "                        ST_GeomFromText(signals.point_signal))\n",
    "    \"\"\").cache()\n",
    "\n",
    "# .cache() can save processing time when calling the same dataframe more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time signals_stores_sdf.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-leather",
   "metadata": {},
   "source": [
    "# HERE I STUCKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time signals_stores_sdf.show(5) \n",
    "# ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker \n",
    "# for task 186,5,main] java.lang.OutOfMemoryError: Java heap space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time signals_stores_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time signals_stores_df = signals_stores_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_df = signals_stores_df.rename(columns={\"device_id\": \"store_id\", \n",
    "                                                      \"lat\": \"store_name\", \n",
    "                                                      \"lon\": \"polygon_store\", \n",
    "                                                      \"date\": \"device_id\", \n",
    "                                                      \"point_signal\": \"lat\", \n",
    "                                                      \"store_id\": \"lon\", \n",
    "                                                      \"store_name\": \"date\", \n",
    "                                                      \"polygon_store\": \"point_signal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_stores_df.to_csv(\"../signals_stores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-logic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-eagle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-prairie",
   "metadata": {},
   "source": [
    "### close the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-digest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
